{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "instrumental-unknown",
   "metadata": {},
   "source": [
    "# Test of GNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "covered-birmingham",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:08:42.296720Z",
     "start_time": "2021-04-21T07:08:40.344454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import cogdl\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grave-prince",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:08:42.300062Z",
     "start_time": "2021-04-21T07:08:42.298214Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-barbados",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dramatic-superintendent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:30:39.449913Z",
     "start_time": "2021-04-23T05:30:39.447681Z"
    }
   },
   "outputs": [],
   "source": [
    "from grb.dataset.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continued-employer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:30:39.983898Z",
     "start_time": "2021-04-23T05:30:39.971185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'cora' loaded.\n",
      "    Number of nodes: 2708.\n",
      "    Number of edges: 5242.\n",
      "    Number of features: 1433.\n",
      "    Number of classes: 7.\n",
      "    Number of train samples: 140.\n",
      "    Number of val samples: 500.\n",
      "    Number of test samples: 1000.\n",
      "    Feature range: [0.0000, 1.0000]\n"
     ]
    }
   ],
   "source": [
    "dataset = DataLoader('cora', mode='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "higher-orange",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T05:30:42.570815Z",
     "start_time": "2021-04-23T05:30:42.567788Z"
    }
   },
   "outputs": [],
   "source": [
    "adj = dataset.adj\n",
    "adj_tensor = dataset.adj_tensor\n",
    "features = dataset.features\n",
    "labels = dataset.labels\n",
    "num_features = dataset.num_features\n",
    "num_classes = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "actual-corruption",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:08:47.160088Z",
     "start_time": "2021-04-21T07:08:47.156443Z"
    }
   },
   "outputs": [],
   "source": [
    "from grb.utils import fix_seed, get_num_params\n",
    "\n",
    "fix_seed(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-width",
   "metadata": {},
   "source": [
    "# GCN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "common-spread",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:08:47.843047Z",
     "start_time": "2021-04-21T07:08:47.838425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 23335.\n",
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): GCNConv(\n",
      "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "    )\n",
      "    (1): GCNConv(\n",
      "      (linear): Linear(in_features=16, out_features=16, bias=True)\n",
      "    )\n",
      "    (2): GCNConv(\n",
      "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from grb.model.gcn import GCN\n",
    "\n",
    "model = GCN(in_features=num_features, out_features=num_classes, hidden_features=[16], activation=F.relu)\n",
    "print(\"Number of parameters: {}.\".format(get_num_params(model)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-baking",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equal-display",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:08:49.588703Z",
     "start_time": "2021-04-21T07:08:49.556506Z"
    }
   },
   "outputs": [],
   "source": [
    "from grb.model.trainer import Trainer\n",
    "from grb.utils.normalize import GCNAdjNorm\n",
    "\n",
    "adam = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "kwargs = {'adj_norm_func': GCNAdjNorm}\n",
    "trainer = Trainer(dataset=dataset, optimizer=adam, loss=F.nll_loss, device='cpu', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electronic-irish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:08:58.123497Z",
     "start_time": "2021-04-21T07:08:58.118714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (layers): ModuleList(\n",
       "    (0): GCNConv(\n",
       "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
       "    )\n",
       "    (1): GCNConv(\n",
       "      (linear): Linear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (2): GCNConv(\n",
       "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'model_gcn_cora.pt'\n",
    "trainer.set_config(n_epoch=200, eval_every=10, save_path='../grb/model/saved_models/' + model_name)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "developmental-modification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T07:09:14.218839Z",
     "start_time": "2021-04-21T07:09:00.490877Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 1.9597 | Train Acc 0.1429 | Val Acc 0.0580\n",
      "Epoch 00010 | Loss 1.9290 | Train Acc 0.1929 | Val Acc 0.1940\n",
      "Epoch 00020 | Loss 1.8534 | Train Acc 0.3357 | Val Acc 0.2580\n",
      "Epoch 00030 | Loss 1.6814 | Train Acc 0.4143 | Val Acc 0.2620\n",
      "Epoch 00040 | Loss 1.4250 | Train Acc 0.5214 | Val Acc 0.3300\n",
      "Epoch 00050 | Loss 1.1388 | Train Acc 0.5929 | Val Acc 0.4140\n",
      "Epoch 00060 | Loss 0.9187 | Train Acc 0.6786 | Val Acc 0.4760\n",
      "Epoch 00070 | Loss 0.7197 | Train Acc 0.7857 | Val Acc 0.5160\n",
      "Epoch 00080 | Loss 0.6497 | Train Acc 0.7857 | Val Acc 0.5540\n",
      "Epoch 00090 | Loss 0.5425 | Train Acc 0.8357 | Val Acc 0.5620\n",
      "Epoch 00100 | Loss 0.4783 | Train Acc 0.8286 | Val Acc 0.6240\n",
      "Epoch 00110 | Loss 0.4179 | Train Acc 0.8786 | Val Acc 0.6280\n",
      "Epoch 00120 | Loss 0.3253 | Train Acc 0.9071 | Val Acc 0.6160\n",
      "Epoch 00130 | Loss 0.2559 | Train Acc 0.9429 | Val Acc 0.6260\n",
      "Epoch 00140 | Loss 0.2715 | Train Acc 0.9286 | Val Acc 0.6260\n",
      "Epoch 00150 | Loss 0.2506 | Train Acc 0.9214 | Val Acc 0.6520\n",
      "Epoch 00160 | Loss 0.2538 | Train Acc 0.9214 | Val Acc 0.6320\n",
      "Epoch 00170 | Loss 0.1777 | Train Acc 0.9571 | Val Acc 0.6560\n",
      "Epoch 00180 | Loss 0.1451 | Train Acc 0.9643 | Val Acc 0.6320\n",
      "Epoch 00190 | Loss 0.1509 | Train Acc 0.9643 | Val Acc 0.6080\n",
      "Epoch 00200 | Loss 0.1565 | Train Acc 0.9571 | Val Acc 0.6320\n",
      "Epoch 00210 | Loss 0.1395 | Train Acc 0.9357 | Val Acc 0.6520\n",
      "Epoch 00220 | Loss 0.1620 | Train Acc 0.9429 | Val Acc 0.6440\n",
      "Epoch 00230 | Loss 0.1407 | Train Acc 0.9357 | Val Acc 0.6440\n",
      "Epoch 00240 | Loss 0.1294 | Train Acc 0.9571 | Val Acc 0.6560\n",
      "Epoch 00250 | Loss 0.1312 | Train Acc 0.9714 | Val Acc 0.6740\n",
      "Epoch 00260 | Loss 0.1025 | Train Acc 0.9714 | Val Acc 0.6440\n",
      "Epoch 00270 | Loss 0.1069 | Train Acc 0.9714 | Val Acc 0.6400\n",
      "Epoch 00280 | Loss 0.0386 | Train Acc 0.9929 | Val Acc 0.6680\n",
      "Epoch 00290 | Loss 0.0840 | Train Acc 0.9786 | Val Acc 0.6840\n",
      "Epoch 00300 | Loss 0.1372 | Train Acc 0.9500 | Val Acc 0.6320\n",
      "Epoch 00310 | Loss 0.0940 | Train Acc 0.9643 | Val Acc 0.6500\n",
      "Epoch 00320 | Loss 0.1015 | Train Acc 0.9714 | Val Acc 0.6800\n",
      "Epoch 00330 | Loss 0.0974 | Train Acc 0.9643 | Val Acc 0.6420\n",
      "Epoch 00340 | Loss 0.0727 | Train Acc 0.9857 | Val Acc 0.6720\n",
      "Epoch 00350 | Loss 0.0885 | Train Acc 0.9714 | Val Acc 0.6520\n",
      "Epoch 00360 | Loss 0.1198 | Train Acc 0.9571 | Val Acc 0.6480\n",
      "Epoch 00370 | Loss 0.0689 | Train Acc 0.9857 | Val Acc 0.6380\n",
      "Epoch 00380 | Loss 0.0544 | Train Acc 0.9929 | Val Acc 0.6440\n",
      "Epoch 00390 | Loss 0.0787 | Train Acc 0.9714 | Val Acc 0.6480\n",
      "Epoch 00400 | Loss 0.0956 | Train Acc 0.9643 | Val Acc 0.6400\n",
      "Epoch 00410 | Loss 0.0771 | Train Acc 0.9786 | Val Acc 0.6520\n",
      "Epoch 00420 | Loss 0.0357 | Train Acc 0.9929 | Val Acc 0.6240\n",
      "Epoch 00430 | Loss 0.0739 | Train Acc 0.9714 | Val Acc 0.6380\n",
      "Epoch 00440 | Loss 0.0919 | Train Acc 0.9786 | Val Acc 0.6720\n",
      "Epoch 00450 | Loss 0.0911 | Train Acc 0.9786 | Val Acc 0.6540\n",
      "Epoch 00460 | Loss 0.0439 | Train Acc 0.9857 | Val Acc 0.6540\n",
      "Epoch 00470 | Loss 0.0491 | Train Acc 0.9929 | Val Acc 0.6540\n",
      "Epoch 00480 | Loss 0.0604 | Train Acc 0.9857 | Val Acc 0.6580\n",
      "Epoch 00490 | Loss 0.0353 | Train Acc 0.9929 | Val Acc 0.6560\n",
      "Epoch 00500 | Loss 0.0451 | Train Acc 0.9857 | Val Acc 0.6280\n",
      "Epoch 00510 | Loss 0.1889 | Train Acc 0.9571 | Val Acc 0.6440\n",
      "Epoch 00520 | Loss 0.0754 | Train Acc 0.9786 | Val Acc 0.6380\n",
      "Epoch 00530 | Loss 0.0399 | Train Acc 1.0000 | Val Acc 0.6680\n",
      "Epoch 00540 | Loss 0.0493 | Train Acc 0.9929 | Val Acc 0.6300\n",
      "Epoch 00550 | Loss 0.0599 | Train Acc 0.9643 | Val Acc 0.6380\n",
      "Epoch 00560 | Loss 0.0365 | Train Acc 1.0000 | Val Acc 0.6500\n",
      "Epoch 00570 | Loss 0.0410 | Train Acc 0.9929 | Val Acc 0.6580\n",
      "Epoch 00580 | Loss 0.0537 | Train Acc 0.9786 | Val Acc 0.6480\n",
      "Epoch 00590 | Loss 0.0490 | Train Acc 0.9786 | Val Acc 0.6360\n",
      "Epoch 00600 | Loss 0.0884 | Train Acc 0.9643 | Val Acc 0.6140\n",
      "Epoch 00610 | Loss 0.0451 | Train Acc 0.9929 | Val Acc 0.6320\n",
      "Epoch 00620 | Loss 0.0912 | Train Acc 0.9786 | Val Acc 0.6360\n",
      "Epoch 00630 | Loss 0.0281 | Train Acc 1.0000 | Val Acc 0.6540\n",
      "Epoch 00640 | Loss 0.0424 | Train Acc 0.9857 | Val Acc 0.6580\n",
      "Epoch 00650 | Loss 0.0538 | Train Acc 0.9857 | Val Acc 0.6560\n",
      "Epoch 00660 | Loss 0.0558 | Train Acc 0.9857 | Val Acc 0.6560\n",
      "Epoch 00670 | Loss 0.0497 | Train Acc 0.9929 | Val Acc 0.6500\n",
      "Epoch 00680 | Loss 0.0552 | Train Acc 0.9786 | Val Acc 0.6580\n",
      "Epoch 00690 | Loss 0.0470 | Train Acc 0.9786 | Val Acc 0.6320\n",
      "Epoch 00700 | Loss 0.0729 | Train Acc 0.9929 | Val Acc 0.6280\n",
      "Epoch 00710 | Loss 0.0265 | Train Acc 0.9929 | Val Acc 0.6620\n",
      "Epoch 00720 | Loss 0.0261 | Train Acc 1.0000 | Val Acc 0.6620\n",
      "Epoch 00730 | Loss 0.0974 | Train Acc 0.9643 | Val Acc 0.6580\n",
      "Epoch 00740 | Loss 0.0509 | Train Acc 0.9786 | Val Acc 0.6800\n",
      "Epoch 00750 | Loss 0.0420 | Train Acc 0.9929 | Val Acc 0.6540\n",
      "Epoch 00760 | Loss 0.0241 | Train Acc 1.0000 | Val Acc 0.6460\n",
      "Epoch 00770 | Loss 0.0477 | Train Acc 0.9857 | Val Acc 0.6520\n",
      "Epoch 00780 | Loss 0.0341 | Train Acc 0.9857 | Val Acc 0.6440\n",
      "Epoch 00790 | Loss 0.0362 | Train Acc 0.9857 | Val Acc 0.6640\n",
      "Epoch 00800 | Loss 0.0381 | Train Acc 0.9857 | Val Acc 0.6580\n",
      "Epoch 00810 | Loss 0.0291 | Train Acc 0.9857 | Val Acc 0.6540\n",
      "Epoch 00820 | Loss 0.0456 | Train Acc 0.9857 | Val Acc 0.6500\n",
      "Epoch 00830 | Loss 0.0560 | Train Acc 0.9857 | Val Acc 0.6340\n",
      "Epoch 00840 | Loss 0.0245 | Train Acc 1.0000 | Val Acc 0.6620\n",
      "Epoch 00850 | Loss 0.1165 | Train Acc 0.9643 | Val Acc 0.6540\n",
      "Epoch 00860 | Loss 0.0316 | Train Acc 0.9857 | Val Acc 0.6520\n",
      "Epoch 00870 | Loss 0.0278 | Train Acc 1.0000 | Val Acc 0.6500\n",
      "Epoch 00880 | Loss 0.0213 | Train Acc 0.9929 | Val Acc 0.6520\n",
      "Epoch 00890 | Loss 0.0480 | Train Acc 0.9857 | Val Acc 0.6680\n",
      "Epoch 00900 | Loss 0.0298 | Train Acc 0.9929 | Val Acc 0.6360\n",
      "Epoch 00910 | Loss 0.0352 | Train Acc 0.9929 | Val Acc 0.6460\n",
      "Epoch 00920 | Loss 0.0484 | Train Acc 0.9857 | Val Acc 0.6520\n",
      "Epoch 00930 | Loss 0.0629 | Train Acc 0.9786 | Val Acc 0.6460\n",
      "Epoch 00940 | Loss 0.0371 | Train Acc 0.9857 | Val Acc 0.6600\n",
      "Epoch 00950 | Loss 0.0463 | Train Acc 0.9786 | Val Acc 0.6360\n",
      "Epoch 00960 | Loss 0.0409 | Train Acc 0.9929 | Val Acc 0.6480\n",
      "Epoch 00970 | Loss 0.0503 | Train Acc 0.9786 | Val Acc 0.6580\n",
      "Epoch 00980 | Loss 0.0394 | Train Acc 0.9786 | Val Acc 0.6580\n",
      "Epoch 00990 | Loss 0.0331 | Train Acc 0.9857 | Val Acc 0.6460\n"
     ]
    }
   ],
   "source": [
    "trainer.train(model, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-monkey",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "after-roads",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:54:44.840740Z",
     "start_time": "2021-04-21T06:54:44.828823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7060\n"
     ]
    }
   ],
   "source": [
    "from grb.utils import evaluator\n",
    "\n",
    "model.eval()\n",
    "pred = model.forward(features, adj_tensor, dropout=0)\n",
    "pred_label = torch.argmax(pred, dim=1)\n",
    "acc = evaluator.eval_acc(pred, labels, mask=dataset.test_mask)\n",
    "print(\"Test accuracy: {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-hours",
   "metadata": {},
   "source": [
    "# GAT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mechanical-balloon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T09:46:31.008652Z",
     "start_time": "2021-04-21T09:46:30.788048Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'in_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d6edb78813be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgrb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of parameters: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_num_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'in_features'"
     ]
    }
   ],
   "source": [
    "from grb.model.gat import GAT\n",
    "\n",
    "model = GAT(num_layers=3, num_heads=, head_dim, activation=F.leaky_relu)\n",
    "print(\"Number of parameters: {}.\".format(get_num_params(model)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-boulder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-butter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
